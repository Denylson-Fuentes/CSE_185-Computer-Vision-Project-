{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "received-force",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, AveragePooling2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "improved-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting images with contour lines\n",
    "def get_contours(path):\n",
    "    all_img = []\n",
    "    for entry in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, entry)):\n",
    "            \n",
    "            image = os.path.join(path, entry)\n",
    "            #print(image)\n",
    "            img = cv2.imread(image)\n",
    "            img = img[200:1251, 100:1650]\n",
    "\n",
    "            imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            ret,thresh = cv2.threshold(imgray, 110, 150, 0)\n",
    "\n",
    "            contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "            img = cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "            \n",
    "            cv2.imwrite(image, img)\n",
    "   \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "adjustable-profile",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) ..\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-269-fb11f1056af5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"./Covid19-dataset/test/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mall_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mall_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-268-34f8d28d6825>\u001b[0m in \u001b[0;36mall_types\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtype_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mcurrent_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtype_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mget_contours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-267-429671cd922c>\u001b[0m in \u001b[0;36mget_contours\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1251\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1650\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mimgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#             ret,thresh = cv2.threshold(imgray, 110, 150, 0)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) ..\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "Normal_path  = \"./Covid19-dataset/train/Normal\"\n",
    "Covid_path  = \"./Covid19-dataset/train/Covid\"\n",
    "Viral_path  = \"./Covid19-dataset/train/Viral Pneumonia\"\n",
    "\n",
    "test_normal_path = \"./Covid19-dataset/test/Normal\"\n",
    "test_covid_path = \"./Covid19-dataset/test/Covid\"\n",
    "test_viral_path = \"./Covid19-dataset/test/Viral Pneumonia\"\n",
    "\n",
    "get_contours(Normal_path)\n",
    "get_contours(Covid_path)\n",
    "get_contours(Viral_path)\n",
    "get_contours(test_covid_path)\n",
    "get_contours(test_normal_path)\n",
    "get_contours(test_viral_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "informative-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = 0.3\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1/255,\n",
    "    zoom_range = 0.1,\n",
    "    fill_mode = \"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "operational-guyana",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (251,), y.shape = (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-237-212b4a8f2349>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_imgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m test_data = test_datagen.flow(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow\u001b[1;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, subset)\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[0msave_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_prefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m         \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m         subset=subset)\n\u001b[0m\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   def flow_from_directory(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m         **kwargs)\n\u001b[0m\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, dtype)\u001b[0m\n\u001b[0;32m     87\u001b[0m                              \u001b[1;34m'should have the same length. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                              \u001b[1;34m'Found: x.shape = %s, y.shape = %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m                              (np.asarray(x).shape, np.asarray(y).shape))\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             raise ValueError('`x` (images tensor) and `sample_weight` '\n",
      "\u001b[1;31mValueError\u001b[0m: `x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (251,), y.shape = (3,)"
     ]
    }
   ],
   "source": [
    "labels = ['Normal', 'Covid', 'Viral Pnuemonia']\n",
    "\n",
    "train_data = train_datagen.flow(\n",
    "    x = training_imgs,\n",
    "    y = labels,\n",
    "    batch_size = 4\n",
    ")\n",
    "test_data = test_datagen.flow(\n",
    "    x = test_imgs,\n",
    "    y = labels,\n",
    "    batch_size = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "interpreted-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "CNN_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "sitting-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build and Configure the model\n",
    "\n",
    "#1st Convolution layer\n",
    "CNN_model.add(Conv2D(32, kernel_size = (3,3), padding = \"same\", activation = 'relu'))\n",
    "CNN_model.add(Conv2D(32, kernel_size = (5,5), padding = \"valid\"))\n",
    "CNN_model.add(MaxPooling2D(pool_size = (3,3), padding = \"valid\"))\n",
    "\n",
    "#2nd Convolution layer\n",
    "CNN_model.add(Conv2D(64, kernel_size = (5,5), padding = \"same\", activation = 'relu'))\n",
    "CNN_model.add(Conv2D(128, kernel_size = (3,3), padding = \"valid\"))\n",
    "CNN_model.add(MaxPooling2D(pool_size = (3,3), padding = \"valid\"))\n",
    "\n",
    "CNN_model.add(Flatten())\n",
    "\n",
    "CNN_model.add(Dense(units = 128, activation = 'relu'))\n",
    "CNN_model.add(Dense(units = 64, activation = 'relu'))\n",
    "CNN_model.add(Dense(units = 16, activation = 'relu'))\n",
    "CNN_model.add(Dense(units = 3, activation = 'sigmoid'))\n",
    "\n",
    "CNN_model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ready-coaching",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-232-f962d4350fdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mtraining_imgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtraining_imgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1040\u001b[0m               (x, y, sample_weight), validation_split=validation_split))\n\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m       val_x, val_y, val_sample_weight = (\n\u001b[0;32m   1044\u001b[0m           data_adapter.unpack_x_y_sample_weight(validation_data))\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "#Fit the model now\n",
    "CNN_model.fit(\n",
    "    training_imgs,\n",
    "    epochs = 10,\n",
    "    validation_data= training_imgs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-poster",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
